# ğŸ§  EEG Fogâ€“Cloud Analytics Pipeline

## ğŸ“Œ 1. VisiÃ³n general

Este proyecto implementa una **arquitectura Fogâ€“Cloud** para el procesamiento de eventos EEG en tiempo real(simulado), orientada a la **detecciÃ³n temprana de sesiones sospechosas**, el **almacenamiento histÃ³rico de eventos**, la **analÃ­tica offline(posteriormente)** y la **emisiÃ³n de alertas automÃ¡ticas**.

La soluciÃ³n combina **procesamiento cercano a la fuente (Fog Computing)** con **servicios serverless en AWS**, logrando un sistema escalable, desacoplado y adecuado para entornos clÃ­nicos donde la latencia, el costo y la trazabilidad son factores crÃ­ticos.

---

## ğŸ¯ 2. Objetivos del proyecto

- Procesar eventos EEG de forma continua y escalable.
- Mantener estado agregado por sesiÃ³n (ventanas totales y sospechosas).
- Almacenar eventos para anÃ¡lisis histÃ³rico.
- Permitir consultas analÃ­ticas mediante SQL.
- Emitir alertas automÃ¡ticas cuando se superan umbrales clÃ­nicos.
- Demostrar un enfoque arquitectÃ³nico Fog + Cloud realista.

---

## ğŸ—ï¸ 3. Arquitectura general

![arquitectura](docs/screenshots/arquitectura.png)

La arquitectura estÃ¡ dividida en tres grandes capas:

- **Obtencion de seÃ±ales cerebrales**: ColocaciÃ³n de electrodos en la cabeza de pacientes en observaciÃ³n.
- **Fog Computing**: procesamiento cercano a la fuente (hospital).
- **Cloud Computing (AWS)**: ingestiÃ³n, persistencia, analÃ­tica y alertas.

---

## ğŸ”„ 4. Flujo general de datos

1. Captura de seÃ±ales EEG en pacientes hospitalarios.
2. Procesamiento inicial en nodos Fog.
3. EnvÃ­o de eventos EEG a Amazon Kinesis Data Streams.
4. Procesamiento de eventos mediante AWS Lambda.
5. Almacenamiento de eventos en Amazon S3.
6. CatalogaciÃ³n de datos con AWS Glue Data Catalog.
7. Consultas analÃ­ticas usando Amazon Athena.
8. Almacenamiento de resultados de consultas en S3.
9. Mantenimiento del estado de sesiÃ³n en Amazon DynamoDB.
10. EvaluaciÃ³n de umbrales clÃ­nicos.
11. NotificaciÃ³n de alertas mediante Amazon SNS.

---

## ğŸŒ«ï¸ 5. Capa Fog Computing

### 5.1 Rol del Fog

La capa Fog permite realizar procesamiento **cercano a los pacientes**, reduciendo:

- Latencia
- TrÃ¡fico innecesario hacia la nube
- Costos de almacenamiento y cÃ³mputo

### 5.2 Funciones principales

- Lectura de archivos EEG ( formato *.edf* ).
- SegmentaciÃ³n/procesamiento en ventanas temporales de 4 *seg*.
- Inferencia con un modelo ligero llamado ligera *EEGNet* [1].
- Conteo de ventanas sospechosas.
- DecisiÃ³n condicional de subida de EDF completos a la nube.

### 5.3 JustificaciÃ³n

El Fog actÃºa como un **primer filtro inteligente**, enviando a la nube solo informaciÃ³n relevante y eventos procesados, lo cual es fundamental en escenarios clÃ­nicos reales.

### 5.4 SimulaciÃ³n

La simulaciÃ³n consiste en la extracciÃ³n de las seÃ±ales cerebrales de varios pacientes de dos habitaciones de un hospital, esta simulacion se hace en dos terminales de linux de tal manera que cada habitaciÃ³n(terminal) envia de manera independiente las seÃ±ales al componente Fog:

#### 5.4.1 ***SimulaciÃ³nHabitacion #1(Terminal #1)***:

```bash
python -m fog.room_simulators.run_room --room room_A 
```

![roomA1](docs/screenshots/roomA_1.png)

![roomA2](docs/screenshots/roomA_2.png)


#### 5.4.2 ***SimulaciÃ³nHabitacion #2(Terminal #2)***:

```bash
python -m fog.room_simulators.run_room --room room_B 
```

![roomB1](docs/screenshots/roomB_1.png)

![roomB2](docs/screenshots/roomB_2.png)

---

## â˜ï¸ 6. Capa Cloud Computing (AWS)

### ğŸ“¡ Amazon Kinesis Data Streams

**Rol:** Ingestar eventos EEG en tiempo real.  
**JustificaciÃ³n:** Permite mÃºltiples productores (nodos Fog), desacopla la ingesta del procesamiento y soporta flujos continuos de datos.

![kinesis](docs/screenshots/kinesis.png)

---

### âš™ï¸ AWS Lambda â€“ Procesamiento de eventos

**Rol:** Procesar eventos EEG.  
**Responsabilidades:**

- Decodificar eventos provenientes de Kinesis.
- Persistir eventos en S3.
- Actualizar el estado de sesiÃ³n en DynamoDB.

Este Lambda se ejecuta de forma **event-driven** y escala automÃ¡ticamente segÃºn la carga.

El evento que persistimos en S3 tiene el siguiente formato:

![lambda1](docs/screenshots/lambda1.png)

Ademas hacemos una actualizacion del total de ventanas y de las ventanas sospechosas del paciente `event[patient_id]`:

![lambda2](docs/screenshots/lambda1_2.png)

---

### ğŸ—‚ï¸ Amazon S3 â€“ Data Lake de eventos

**Rol:** Almacenar eventos EEG histÃ³ricos.  
**JustificaciÃ³n:** S3 actÃºa como un data lake de bajo costo, altamente escalable y base para la analÃ­tica offline.

Para el iguiente paciente estructurado con la fecha podemos ver los `.json` de todos los eventos de dicho paciente:

![s31](docs/screenshots/s3_1.png)

![s32](docs/screenshots/s3_2.png)

Ademas como criterio que se establecio en el componente fog se sube toda la seÃ±al completa `.edf` file: 

![s33](docs/screenshots/s3_3.png)


![s34](docs/screenshots/s3_4.png)

---

### ğŸ“Š Amazon DynamoDB â€“ Estado de sesiones

**Rol:** Mantener estado agregado por sesiÃ³n.  
**InformaciÃ³n almacenada:**

- Total de ventanas procesadas.
- Total de ventanas sospechosas.
- Identificadores de paciente y sesiÃ³n.

**JustificaciÃ³n:** DynamoDB ofrece baja latencia y es ideal para contadores y estados incrementales.

A continuaciÃ³n se presenta la tabla actualizada de los dos clientes, sus ventanas totales y ventanas sospechosas.

![dynamo](docs/screenshots/dynamo.png)

---

### ğŸ§¾ AWS Glue Data Catalog

**Rol:** Catalogar los eventos almacenados en S3.  
**JustificaciÃ³n:** Permite descubrir el esquema de los datos y habilita consultas SQL sin necesidad de definir tablas manualmente.

Se define el siguiente esquema que tiene com source el data lake que persistimos en s3:

![dynamo](docs/screenshots/glue.png)


---

### ğŸ” Amazon Athena

**Rol:** Consultar eventos EEG mediante SQL.  
**Ejemplos de consultas:**

Una vez definido nuestro catalogo con `AWS Glue` podemos hacer la siguientes consultas:

- Â¿CuÃ¡ntas ventanas sospechosas por paciente?

```sql
--- CuÃ¡ntas ventanas sospechosas por paciente?
SELECT
    patient_id,
    COUNT(*) AS suspected_windows
FROM eeg_seizure_events_db.eeg_window_events
WHERE suspected = true
GROUP BY patient_id
ORDER BY suspected_windows DESC;
```

![sql1](docs/screenshots/sql1.png)

- Â¿CuÃ¡ntas sesiones activas por dÃ­a?

```sql
--- Â¿CuÃ¡ntas sesiones activas por dÃ­a?
SELECT
    DATE(substr(timestamp, 1, 10)) AS event_date,
    COUNT(DISTINCT session_id) AS active_sessions
FROM eeg_seizure_events_db.eeg_window_events
GROUP BY DATE(substr(timestamp, 1, 10))
ORDER BY event_date;
```

![sql2](docs/screenshots/sql2.png)

- Â¿En quÃ© cuartos ocurre mayor frecuencia de eventos?

```sql
--- Â¿En quÃ© cuartos ocurre mayor frecuencia de eventos?
SELECT
    room_id,
    COUNT(*) AS total_events,
    SUM(CASE WHEN suspected THEN 1 ELSE 0 END) AS suspected_events
FROM eeg_seizure_events_db.eeg_window_events
GROUP BY room_id
ORDER BY suspected_events DESC;
```

![sql3](docs/screenshots/sql3.png)

- EvoluciÃ³n temporal de scores sospechosos.
- Sesiones que superaron un umbral clÃ­nico.

Los resultados de las consultas se almacenan automÃ¡ticamente en S3.

![athena1](docs/screenshots/athena_s3_1.png)

![athena2](docs/screenshots/athena_s3_2.png)


---

### ğŸš¨ AWS Lambda â€“ EvaluaciÃ³n de alertas

**Rol:** Detectar sesiones crÃ­ticas.  
**Trigger:** DynamoDB Streams.  
**Responsabilidades:**

- Evaluar si una sesiÃ³n supera un umbral configurable.
- Construir mensajes de alerta.
- Publicar notificaciones en SNS.

Este Lambda estÃ¡ desacoplado del procesamiento principal para mantener responsabilidades claras.

```python
for record in  records:
        print("record index:", idx)
        idx+=1
        print(f"[handler] Processing record: {json.dumps(record)}")
        if record["eventName"] not in ("INSERT", "MODIFY"):
            continue

        new_image = record["dynamodb"].get("NewImage")
        print(f"[handler] NewImage: {json.dumps(new_image)}")
        if not new_image:
            continue

        suspected = int(new_image["suspected_windows"]["N"])
        total = int(new_image["windows_total"]["N"])

        if suspected >= THRESHOLD:
            print("[handler] suspected >= THRESHOLD, sending alert")
            message = {
                "alert_type": "SESSION_THRESHOLD_EXCEEDED",
                "patient_id": new_image["pk"]["S"],
                "session_id": new_image["sk"]["S"],
                "suspected_windows": suspected,
                "windows_total": total,
            }

            sns.publish(
                TopicArn=SNS_TOPIC_ARN,
                Subject="âš ï¸ Alerta EEG: sesiÃ³n sospechosa",
                Message=json.dumps(message, indent=2),
            )
```

---

### ğŸ“£ Amazon SNS â€“ Sistema de notificaciones

**Rol:** Notificar alertas clÃ­nicas.  
**Canales:** Email (extensible a SMS, HTTP, apps).  
**JustificaciÃ³n:** SNS permite desacoplar la generaciÃ³n de alertas del canal de entrega.

![alerta](docs/screenshots/alert.jpeg)


---

## ğŸ§  7. JustificaciÃ³n de decisiones arquitectÃ³nicas

- **Fog + Cloud:** balance entre latencia, costo y escalabilidad.
- **Dos Lambdas:** separaciÃ³n clara entre procesamiento y evaluaciÃ³n.
- **Kinesis:** ingesta robusta y desacoplada.
- **DynamoDB:** estado incremental de baja latencia.
- **S3 + Athena:** analÃ­tica flexible y econÃ³mica.
- **SNS:** notificaciones desacopladas y extensibles.

---

## ğŸ§± 8. Infraestructura como CÃ³digo (IaC)

Toda la infraestructura Cloud estÃ¡ definida usando **Pulumi**, lo que permite:

- Reproducibilidad
- Versionado
- Despliegues controlados
- AuditorÃ­a de cambios

Luego el entorno virtual ya creado e instalado los requirements.txt, hacemos:

```bash
pulumi up --yes
```

![pulumiUp](docs/screenshots/pulumi.png)

---

## ğŸ“ 9. Estructura del proyecto

```text
eeg-seizure-fog-cloud-analytics-pipeline/
â”œâ”€â”€ fog/
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ room_simulator/
â”‚   â”œâ”€â”€ venv_fog/
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ cloud/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ streaming/
â”‚   â”‚   â”œâ”€â”€ compute/
â”‚   â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ messaging/
â”‚   â”‚   â”œâ”€â”€ security/
â”‚   â”‚   â””â”€â”€ database/
â”‚   â”œâ”€â”€ lambda_src/
â”‚   â”œâ”€â”€ __main__.py
â”‚   â””â”€â”€ Pulumi.yaml
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ screenshots/
â”‚       â”œâ”€â”€ arquitectura.png
â”‚       â”œâ”€â”€ fog_pipeline.png
â”‚       â”œâ”€â”€ kinesis_logs.png
â”‚       â”œâ”€â”€ athena_queries.png
â”‚       â””â”€â”€ sns_alert.png
â””â”€â”€ README.md
```

---

## ğŸ“ 10. Referencias

- [1] Lawhern, V. J., Solon, A. J., Waytowich, N. R., Gordon, S. M., Hung, C. P., & Lance, B. J. (2018). EEGNet: a compact convolutional neural network for EEG-based brainâ€“computer interfaces. Journal of neural engineering, 15(5), 056013. 

- [2] Godfrey, M. (2023). EEG Analytics Models Using AWS.